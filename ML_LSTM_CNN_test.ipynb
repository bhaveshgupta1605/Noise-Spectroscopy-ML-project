{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras:\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Conv1D, LSTM, Input, ReLU\n",
    "from keras.layers import Flatten, Dropout, Reshape, ZeroPadding1D, Cropping1D\n",
    "from keras.layers import GlobalAveragePooling1D, AveragePooling1D, UpSampling1D, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras import models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, input, output, batch=64, epochs=20,lr=False):\n",
    "  if type(lr) != bool:\n",
    "    K.set_value(model.optimizer.learning_rate, lr)\n",
    "  history = model.fit(input,output,batch,epochs,validation_split=0.1,verbose=1,\n",
    "                  callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7)])\n",
    "  return model, history\n",
    "\n",
    "  # EarlyStopping(monitor='val_loss', patience=25),\n",
    "          # ModelCheckpoint(filepath=filePath, monitor='val_loss', save_best_only=True),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define percent error\n",
    "def percent_error(data_test,data_predict,n_points):\n",
    "  return 100*np.mean(np.abs(data_test-data_predict)/data_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(c_train, s_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Sequential Model\n",
    "\n",
    "Net=Sequential()\n",
    "Net.add(LSTM(250,input_shape=(150,1),return_sequences=True))\n",
    "Net.add(LSTM(150,return_sequences=False))\n",
    "Net.add(Dense(200,activation=\"relu\"))\n",
    "Net.add(Reshape((200,1)))\n",
    "# Net.add(LSTM(60,return_sequences=True))\n",
    "Net.add(LSTM(150,return_sequences=False))\n",
    "# Net.add(LSTM(250,return_sequences=False))\n",
    "# Net.add(Dropout(0.03))\n",
    "# Net.add(LSTM(150,return_sequences=False))\n",
    "Net.add(Dense(250,activation=\"relu\"))\n",
    "Net.add(Dense(501,activation=\"exponential\"))\n",
    "Net.compile(loss='MAPE',optimizer='adam')\n",
    "Net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_lstm = np.sum([K.count_params(w) for w in Net.trainable_weights])\n",
    "trainable_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "start = time.time()\n",
    "lstm, history_lstm = training(Net,x_train,y_train,batch=64,epochs=n_epochs,\n",
    "                              lr=0.001,\n",
    "                              )\n",
    "end = time.time()\n",
    "time_lstm = end - start\n",
    "print(time_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained model\n",
    "lstm.save(trainData_path+'/LSTM_250_150_d200_150_d250_d501_ep200_X32', overwrite=True)\n",
    "\n",
    "# Saving the training history\n",
    "pd.DataFrame(history_lstm.history).to_csv(trainData_path+'/LSTM_250_150_d200_150_d250_d501_ep200_x32_history'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict = Net.predict(x_test)\n",
    "y_predict = loaded_model.predict(x_test)\n",
    "err_predict = percent_error(y_test,y_predict,501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(err_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_lstm,x =np.histogram(err_predict,bins=51,range=[0,50],density=False)\n",
    "x = (x[:-1]+x[1:])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 5\n",
    "rand_set = np.random.randint(0,y_test.shape[0],(n_plot,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_str = [\"#d9ed92\",\"#b5e48c\",\"#99d98c\",\"#76c893\",\"#52b69a\",\"#34a0a4\",\"#168aad\",\"#1a759f\",\"#1e6091\",\"#184e77\"]\n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=('Training History - LSTM','Mean Absolute Error', 'Comparison'))\n",
    "\n",
    "fig.add_scatter(x=np.arange(1,301),y=history_lstm.history['val_loss'],line=dict(width=3,color='royalblue'),opacity=1,name=f'Validation loss',row=1,col=1,showlegend=False)\n",
    "fig.add_trace(go.Bar(x=x,y=hist_lstm,opacity=0.75,name='Error',showlegend=False),row=1,col=2)\n",
    "for i in range(n_plot):\n",
    "  # fig.add_scatter(x=t*1e6,y=x_test[rand_set[i],:],line=dict(width=2,color=color_str[i]),opacity=1,name=f'Input-{rand_set[i]}',row=1,col=3)\n",
    "  fig.add_scatter(x=1e-6*w_train/(2*np.pi),y=y_test[rand_set[i],:],line=dict(width=3,color=color_str[i]),opacity=0.8,name=f'Expected-{rand_set[i]}',showlegend=True,row=1,col=3)\n",
    "  fig.add_scatter(x=1e-6*w_train/(2*np.pi),y=y_predict[rand_set[i],:],line=dict(width=3,color=color_str[i]),opacity=0.8,name=f'Predicted-{rand_set[i]}',showlegend=True,row=1,col=3)\n",
    "\n",
    "fig.update_layout(template=fig_template,\n",
    "                  width = 1400,\n",
    "                  xaxis1 = dict(title='Epochs'),\n",
    "                  yaxis1 = dict(title='Mean absolute error on validation set',type=\"log\",),\n",
    "                  xaxis2 = dict(title='% Error',range=[0,50]),\n",
    "                  yaxis2 = dict(title='Samples'),\n",
    "                  xaxis3 = dict(title='\\N{greek small letter omega}/2\\N{greek small letter pi} (MHz)',\n",
    "                              #  type=\"log\",\n",
    "                              #  range=[,],\n",
    "                               ),\n",
    "                  yaxis3 = dict(title='S(\\N{greek small letter omega})',\n",
    "                              #  range=[-0.1e6,0.1e6],\n",
    "                              #  type=\"log\",\n",
    "\n",
    "                               ),\n",
    "\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = models.load_model(trainData_path+'/LSTM_250_150_d200_150_d250_d501_ep200_X32')\n",
    "# history_stored = pd.read_csv(path+'/cnn_trial'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_cnn = models.load_model(\"/content/gdrive/My Drive/Research/ML_PROJECTS_ON_SUPERCONDUCTING_QUBITS\"+'/CNN/TRAINED_NETWORKS/MODEL_7.36_fil=32_ker=21_dr0.05_ps=2_LRini=0.001_LRmin=1e-05_bs=64_ep=200_nt=5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model0 = models.load_model(trainData_path+'/LSTM_250_150_d200_150_d250_d501_ep400')\n",
    "loaded_model1 = models.load_model(trainData_path+'/LSTM_250_150_d200_150_d250_d501_ep200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0,1,2,9,10,11,12,13,14,18,19,20)\n",
    "select_data = norm_data[(1,14),:]\n",
    "exp_predict0 = loaded_model0.predict(select_data)\n",
    "exp_predict1 = loaded_model1.predict(select_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = loaded_model.predict(data['c_expt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_cnn = loaded_model_cnn.predict(data['c_expt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To extend the noise spectrum to lower frequencies\n",
    "\n",
    "def spectrum_extend(exp_predict,w_train,w_new):\n",
    "  w_lowSize = np.argwhere(w_new<w_train.min()).size\n",
    "  w_lowArg = np.argwhere(w_new<w_train.min())[0]\n",
    "\n",
    "  s_extend = np.zeros((exp_predict.shape[0],w_new.size))\n",
    "  s_extend[:,int(w_lowArg):] = np.repeat(np.mean(exp_predict[:,-4:],axis=1),\n",
    "                                        int(w_lowSize)).reshape(exp_predict.shape[0],int(w_lowSize))\n",
    "  for i in range(exp_predict.shape[0]):\n",
    "    s_extend[i,:int(w_lowArg)] = interpData(w_train,exp_predict[i,:],w_new[:int(w_lowArg)])\n",
    "  return s_extend\n",
    "\n",
    "## Calculate noise using delta-function approximation for 32-pi-pulse sequence\n",
    "\n",
    "def delta_noise(c, t):\n",
    "  w_delta = 32*np.pi/t\n",
    "  s_delta = -np.pi*np.log(c)/t\n",
    "  return s_delta, w_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_delta, w_delta = delta_noise(select_data,T_train)\n",
    "# s_delta, w_delta = delta_noise(x_test,T_train)\n",
    "\n",
    "w_new = np.flipud(np.geomspace(1e3,w_train.max(),1001))\n",
    "\n",
    "s_extend = spectrum_extend(test_predict,w_train,w_new)\n",
    "s_extend_cnn = spectrum_extend(test_predict_cnn,w_train,w_new)\n",
    "\n",
    "c_predict = getCoherence(s_extend,w_new,T_train,32,48e-9)\n",
    "c_predict_cnn = getCoherence(s_extend_cnn,w_new,T_train,32,48e-9)\n",
    "# c_delta = getCoherence(s_delta,w_delta,T_train,32,48e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"/content/gdrive/My Drive/Research/ML_PROJECTS_ON_SUPERCONDUCTING_QUBITS\"+'/CNN/TRAINED_NETWORKS/predictions_Mar13',\n",
    "                    c_expt=data['c_expt'],t_expt=data['xval'],s_predict=s_extend_cnn,w_predict=w_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "color_str = [\"#d9ed92\",\"#b5e48c\",\"#99d98c\",\"#76c893\",\"#52b69a\",\"#34a0a4\",\"#168aad\",\"#1a759f\",\"#1e6091\",\"#184e77\"]\n",
    "n_plot = 10\n",
    "rand_set = np.random.randint(0,data['c_expt'].shape[0],(n_plot,))\n",
    "for j in range(n_plot):\n",
    "  # print(j)\n",
    "  # fig.add_scatter(x=T_train*1e6,y=x_test[rand_set[j],:],line=dict(width=4,color=color_str[j]),opacity=0.8,name=f'Expt {j}')\n",
    "  fig.add_scatter(x=T_train*1e6,y=data['c_expt'][rand_set[j],:],line=dict(width=4,color=color_str[j]),opacity=0.8,name=f'Expt {j}')\n",
    "  fig.add_scatter(x=T_train*1e6,y=c_predict[rand_set[j],:],line=dict(width=3,color=color_str[j]),opacity=1,name=f'Predict {j}')\n",
    "  fig.add_scatter(x=T_train*1e6,y=c_predict_cnn[rand_set[j],:],line=dict(width=3,color=color_str[j]),opacity=1,name=f'Predict_cnn {j}')\n",
    "  # fig.add_scatter(x=T_train*1e6,y=c_delta[rand_set[j],:],line=dict(width=2),opacity=0.8,name=f'Delta {j}')\n",
    "fig.update_layout(template=fig_template,  title = 'Coherence Curves',\n",
    "                  width = 600,\n",
    "                  xaxis = dict(title='Evolution time (\\N{greek small letter mu}s)',\n",
    "                              #  range=[0,400],\n",
    "                               ),\n",
    "                  yaxis = dict(title='Coherence'),\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in range(select_data.shape[0]):\n",
    "  # fig.add_scatter(x=1e-6*w_train/(2*np.pi),y=exp_predict0[i,:],line=dict(width=3),opacity=0.8,showlegend=True,name=f'{i}')\n",
    "  # fig.add_scatter(x=1e-6*w_train/(2*np.pi),y=exp_predict1[i,:],line=dict(width=3),opacity=0.8,showlegend=True,name=f'{i}')\n",
    "  fig.add_scatter(x=1e-6*w_new/(2*np.pi),y=s_extend[i,:],line=dict(width=3),opacity=1,showlegend=True,name=f'Predict. {i}')\n",
    "\n",
    "fig.add_scatter(x=1e-6*w_delta/(2*np.pi),y=s_delta[1,:],line=dict(width=3,color='grey'),opacity=0.2,showlegend=True,name=f'Approx.')\n",
    "\n",
    "fig.update_layout(template=fig_template,\n",
    "                  width = 600,\n",
    "                  xaxis = dict(title='\\N{greek small letter omega}/2\\N{greek small letter pi} (MHz)',\n",
    "                               type=\"log\",\n",
    "                              #  range=[,],\n",
    "                               ),\n",
    "                  yaxis = dict(title='S(\\N{greek small letter omega})',\n",
    "                               range=[3.6,4.6],\n",
    "                               type=\"log\",\n",
    "\n",
    "                               ),\n",
    "\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for j in range(n_plot):\n",
    "  # fig.add_scatter(x=1e-6*w_train/(2*np.pi),y=y_test[rand_set[j],:],line=dict(width=3,color=color_str[j]),opacity=1,showlegend=True,name=f'Sim. {j}')\n",
    "  # fig.add_scatter(x=1e-6*w_train/(2*np.pi),y=test_predict[rand_set[j],:],line=dict(width=3,color=color_str[j]),opacity=1,showlegend=True,name=f'Pred. {j}')\n",
    "  fig.add_scatter(x=1e-6*w_new/(2*np.pi),y=s_extend[rand_set[j],:],line=dict(width=3,color=color_str[j]),opacity=1,showlegend=True,name=f'Pred.Ex {j}')\n",
    "  fig.add_scatter(x=1e-6*w_new/(2*np.pi),y=s_extend_cnn[rand_set[j],:],line=dict(width=3,color=color_str[j]),opacity=1,showlegend=True,name=f'Pred.Ex_cnn {j}')\n",
    "  # fig.add_scatter(x=1e-6*w_delta/(2*np.pi),y=s_delta[rand_set[j],:],line=dict(width=3,color=color_str[j]),opacity=0.2,showlegend=True,name=f'Approx. {j}')\n",
    "\n",
    "fig.update_layout(template=fig_template,\n",
    "                  width = 600,\n",
    "                  xaxis = dict(title='\\N{greek small letter omega}/2\\N{greek small letter pi} (MHz)',\n",
    "                               type=\"log\",\n",
    "                              #  range=[,],\n",
    "                               ),\n",
    "                  yaxis = dict(title='S(\\N{greek small letter omega})',\n",
    "                               range=[2.6,4.6],\n",
    "                               type=\"log\",\n",
    "\n",
    "                               ),\n",
    "\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model network building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_nb=32\n",
    "kernel_size=32\n",
    "dropout_rate=0.03\n",
    "pool_size=2\n",
    "xtrain_size = np.shape(x_train)[-1]\n",
    "ytrain_size = np.shape(y_train)[-1]\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add( layers.Input( shape=(xtrain_size, 1) ) )\n",
    "model.add( layers.Conv1D(filter_nb,kernel_size,activation=\"relu\", padding='same' ) )\n",
    "model.add( layers.Conv1D(filter_nb,kernel_size,activation=\"relu\", padding='same' ) )\n",
    "model.add( layers.MaxPooling1D( pool_size=pool_size, padding=\"same\") )\n",
    "model.add( layers.Conv1D(filter_nb/2, kernel_size,activation=\"relu\", padding='same' ) )\n",
    "model.add( layers.Flatten() )\n",
    "model.add( layers.Dense(501, activation='relu') )\n",
    "model.add( layers.Reshape((501,1) ))\n",
    "# model.add( layers.MaxPooling1D( pool_size=pool_size, padding=\"same\") )\n",
    "model.add( layers.Conv1D(filter_nb,kernel_size,activation=\"relu\", padding='same' ) )\n",
    "# model.add( layers.MaxPooling1D( pool_size=pool_size, padding=\"same\") )\n",
    "# model.add( layers.Conv1D( filter_nb,kernel_size,activation=\"relu\", padding='same' ) )\n",
    "# model.add( layers.UpSampling1D( size=pool_size ) )\n",
    "# model.add( layers.Conv1D( filter_nb,kernel_size,activation=\"relu\", padding='same' ) )\n",
    "# model.add( layers.UpSampling1D( size=pool_size ) )\n",
    "model.add( layers.Conv1D( filter_nb,kernel_size,activation=\"relu\", padding='same' ) )\n",
    "# model.add( layers.UpSampling1D( size=pool_size ) )\n",
    "# model.add( layers.Conv1D( filter_nb,kernel_size,activation=\"relu\", padding='same' ) )\n",
    "model.add( layers.Conv1D( 1, kernel_size, activation=\"relu\", padding='same' ) )\n",
    "model.add( layers.Flatten() )\n",
    "# model.add( layers.Dense(250, activation='relu') )\n",
    "model.add( layers.Dropout( dropout_rate ) )\n",
    "model.add( layers.Dense(ytrain_size, activation='linear') )\n",
    "model.compile(loss='MAPE',optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_cnn = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "trainable_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 450\n",
    "start = time.time()\n",
    "cnn, history_cnn = training(model,x_train,y_train,batch=64,epochs=n_epochs,\n",
    "                              lr=0.001,\n",
    "                              )\n",
    "end = time.time()\n",
    "time_cnn = end - start\n",
    "print(time_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained model\n",
    "cnn.save(trainData_path+'/cnn_noUpsampling', overwrite=True)\n",
    "\n",
    "# Saving the training history\n",
    "pd.DataFrame(history_cnn.history).to_csv(path+'/cnn_noUpsampling'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = models.load_model(trainData_path+'/cnn_noUpsampling')\n",
    "history_stored = pd.read_csv(path+'/cnn_noUpsampling'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "err_predict = percent_error(y_test,y_predict,501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(err_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_cnn,x =np.histogram(err_predict,bins=51,range=[0,50],density=False)\n",
    "x = (x[:-1]+x[1:])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 5\n",
    "rand_set = np.random.randint(0,y_test.shape[0],(n_plot,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=3, subplot_titles=('Training History - CNN','Mean Absolute Error', 'Comparison'))\n",
    "# history_cnn.history['val_loss']\n",
    "fig.add_scatter(x=np.arange(1,301),y=history_cnn.history['val_loss'],line=dict(width=3,color='royalblue'),opacity=1,name=f'Validation loss',row=1,col=1,showlegend=False)\n",
    "fig.add_trace(go.Bar(x=x,y=hist_cnn,opacity=0.75,name='Error',showlegend=False),row=1,col=2)\n",
    "for i in range(n_plot):\n",
    "  # fig.add_scatter(x=t*1e6,y=x_test[rand_set[i],:],line=dict(width=2,color=color_str[i]),opacity=1,name=f'Input-{rand_set[i]}',row=1,col=3)\n",
    "  fig.add_scatter(x=1e-6*w_train/(2*np.pi),y=y_test[rand_set[i],:],line=dict(width=3,color=color_str[i]),opacity=0.8,name=f'Expected-{rand_set[i]}',showlegend=True,row=1,col=3)\n",
    "  fig.add_scatter(x=1e-6*w_train/(2*np.pi),y=y_predict[rand_set[i],:],line=dict(width=3,color=color_str[i]),opacity=0.8,name=f'Predicted-{rand_set[i]}',showlegend=True,row=1,col=3)\n",
    "\n",
    "fig.update_layout(template=fig_template,\n",
    "                  width = 1000,\n",
    "                  xaxis1 = dict(title='Epochs'),\n",
    "                  yaxis1 = dict(title='Mean absolute error on validation set',type=\"log\",),\n",
    "                  xaxis2 = dict(title='% Error',range=[0,50]),\n",
    "                  yaxis2 = dict(title='Samples'),\n",
    "                  xaxis3 = dict(title='\\N{greek small letter omega}/2\\N{greek small letter pi} (MHz)',\n",
    "                              #  type=\"log\",\n",
    "                              #  range=[,],\n",
    "                               ),\n",
    "                  yaxis3 = dict(title='S(\\N{greek small letter omega})',\n",
    "                              #  range=[-0.1e6,0.1e6],\n",
    "                              #  type=\"log\",\n",
    "\n",
    "                               ),\n",
    "\n",
    "                 )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
